{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.discussion {\n",
       "\tbackground-color: #ccffcc;\n",
       "\tborder-color: #88E97A;\n",
       "\tborder-left: 5px solid #0A8000; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D,\\\n",
    "                                GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall, FalsePositives, FalseNegatives, \\\n",
    "                                    TruePositives, TrueNegatives\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "print(tf.__version__)  # You should see a > 2.0.0 here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "0 GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "print(tf.__version__)  # You should see a > 2.0.0 here!\n",
    "from tf_keras_vis.utils import print_gpus\n",
    "print_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import normalize\n",
    "import tf_keras_vis.utils as utils\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.gradcam import Gradcam\n",
    "\n",
    "np.random.seed(109)\n",
    "tf.random.set_seed(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_addons as tfa\n",
    "#import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1, 8, 1), 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D input\n",
    "# https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\n",
    "\n",
    "a = np.asarray([0,0,0,1,1,0,0,0])\n",
    "display(a.shape, type(a))\n",
    "a = a.reshape(1,8,1) # since keras ip has 3d for 1D conv layer\n",
    "a.shape, a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single filter with input shape of 3; aka 3 elements wide\n",
    "# keras refers to filter shape as kernel size\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(1,3, input_shape=(8,1)))\n",
    "# single filter shape 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default filters are initialized with random weights\n",
    "# can also manually specify weights\n",
    "# define a filter capable of detecting bumps; bias = 0\n",
    "\n",
    "weights = [np.asarray([[[0]], [[1]], [[0]]]), np.asarray([0.0])]\n",
    "# array of shape 3,1,1\n",
    "model.set_weights(weights)\n",
    "\n",
    "# weights must be specified in 3D structure - rows, cols, channels\n",
    "# filter has 1 row, 3 cols and 1 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.]],\n",
       " \n",
       "        [[1.]],\n",
       " \n",
       "        [[0.]]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (1, 6, 1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the single filter to input data\n",
    "yhat = model.predict(a)\n",
    "display(yhat)\n",
    "type(yhat), yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input is 8 element vector\n",
    "1. 3 element filter is applied to 1st 3 inputs by calculating dot product\n",
    "2. Filter is then moved along 1 element & repeat\n",
    "3. Output feature map as 6 elements; input has 8\n",
    "\n",
    "### Example of a 2D conv layer\n",
    "\n",
    "* Vertical line detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain to 8*8 gray image - Single channel\n",
    "b = np.asarray([[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0],\n",
    "[0, 0, 0, 1, 1, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to a Conv 2D layer must be 4D\n",
    "# Number of Samples, Columns, Rows, Channels\n",
    "b = b.reshape(1,8,8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter will be a 2D with 3,3 shape\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1,(3,3), input_shape = (8,8,1)))\n",
    "# single filter with shape 3*3\n",
    "# input shape - cols, rows, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]],\n",
      "\n",
      "\n",
      "       [[[0.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[0.]]]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Define vertical line detector\n",
    "detector = [\n",
    "    [\n",
    "        [[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]],\n",
    "            [[[0]],[[1]],[[0]]\n",
    "            ]\n",
    "]\n",
    "weights = [np.asarray(detector), np.asarray([0.0])]\n",
    "\n",
    "# store weights in the model\n",
    "model.set_weights(weights)\n",
    "\n",
    "# confirm\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 6, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the filter to input data\n",
    "yhat = model.predict(b)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 3.0, 3.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# shape of output feature map is 4D\n",
    "# batch, rows, columns, filters\n",
    "# we have 1 batch and 1 filter; shape = [1,x,x,1]\n",
    "\n",
    "# print the content of the single feature map\n",
    "for r in range(yhat.shape[1]):\n",
    "    # print each column\n",
    "    print([yhat[0,r,c,0] for c in range(yhat.shape[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "\n",
    "* Subsequent application of filters reduces the size of the image\n",
    "* 8*8 image --> 3*3 filter applied 2 times gives 4*4 feature map\n",
    "* This becomes a problem when we develop deep feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 1)           10        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 1)           10        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Example of Stacked concolution layers\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1,(3,3), input_shape = (8,8,1)))\n",
    "model.add(Conv2D(1,(3,3))) # i/p shape needed only for 1st layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 1)           2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Filter with 1 X 1 size\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1,(1,1), input_shape = (8,8,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 1)           65        \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Filter with 8 X 8 size\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1,(8,8), input_shape = (8,8,1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding & Strides\n",
    "\n",
    "* Specified as padding = 'valid' or 'same\n",
    "* strides = (num, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
