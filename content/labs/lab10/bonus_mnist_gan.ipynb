{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baPvz55Y1aEA"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "## MNIST GAN \n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Mark Glickman and Chris Tanner<br/>\n",
    "Author: Rashmi Banthia\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "##### Code merged from \n",
    "##### Tensorflow Tutorial - https://www.tensorflow.org/tutorials/generative/dcgan , Lab 10, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0dWMl5VP1QcR",
    "outputId": "e73db1c3-8c7f-4424-e41d-ee7169f69b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# system libraries \n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# math/numerical libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqi-uUhM1Ue1"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "23UnpHmE1YE0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_train = (X_train - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q863YKHU1rlF"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7OOhbMNX1uvA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe160039190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_dim = 100\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    \n",
    "    adam = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "    #adam = tf.keras.optimizers.Adam(lr=0.0003)\n",
    "    return model\n",
    "\n",
    "g = make_generator_model()\n",
    "print(g.summary())\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = g(noise, training=False)\n",
    "\n",
    "gen_img = tf.reshape(generated_image,(28,-1))\n",
    "plt.imshow(gen_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SVXY-5qc108O",
    "outputId": "bf054ebd-dc73-4862-fb17-df6ceff52d5d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor([[-0.00067243]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(tf.keras.layers.LeakyReLU())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "d = make_discriminator_model()\n",
    "print(d.summary())\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0002) # 1e-4, beta_1=0.5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "d.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "decision = d(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2ZxzrZj16zV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 28, 28, 1)         2330944   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 212865    \n",
      "=================================================================\n",
      "Total params: 2,543,809\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 238,337\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create GAN\n",
    "d.trainable = False\n",
    "inputs = tf.keras.layers.Input(shape=(z_dim, ))\n",
    "hidden = g(inputs)\n",
    "output = d(hidden)\n",
    "gan = tf.keras.Model(inputs, output)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.5)    \n",
    "gan.compile(loss=loss, optimizer=adam, metrics=['accuracy'])\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2O0IPQJ188J"
   },
   "outputs": [],
   "source": [
    "def show_images(imgs):\n",
    "    n_imgs = imgs.shape[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, n_imgs, figsize=(15, 20))\n",
    "    plt.axis('off')\n",
    "    for i in range(n_imgs):\n",
    "        ax[i].imshow(np.clip(imgs[i].reshape(28,28), 0.0, 1.0), cmap='gray')\n",
    "        ax[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JhFUVUsd2BFr",
    "outputId": "9f51a207-6823-4477-e1e8-ada6b4993f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['loss', 'accuracy'], ['loss', 'accuracy'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.metrics_names, gan.metrics_names #(['loss', 'accuracy'], ['loss', 'accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Zn6nkmec2FWb",
    "outputId": "6c7d706a-6519-456c-dbd5-53c5976e5d75"
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[256,64,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-beeaabde6893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_smoother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1132\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# copybara:strip_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1032\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1128\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1129\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1130\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   1131\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   1132\u001b[0m       \"Conv2D\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/usr/share/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[256,64,15,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2D]"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "epochs = 5 #70\n",
    "noise_dim = (100,) #(128,)\n",
    "losses = {\"D\":[], \"G\":[]}\n",
    "\n",
    "y_smoother = 0.1\n",
    "y_real = tf.ones((BATCH_SIZE,1))\n",
    "y_fake = tf.zeros((BATCH_SIZE,1))\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    i = 0\n",
    "    for x_real in train_dataset:\n",
    "        noise = tf.random.normal(shape=(BATCH_SIZE, noise_dim[0]))\n",
    "        x_fake = g.predict_on_batch(noise)\n",
    "        \n",
    "        # train discriminator\n",
    "        d_loss_real = d.train_on_batch(x_real, y_real - y_smoother)\n",
    "        \n",
    "        d_loss_fake = d.train_on_batch(x_fake, y_fake)\n",
    "        \n",
    "        # train generator\n",
    "        noise = tf.random.normal(shape=(BATCH_SIZE, noise_dim[0]))\n",
    "        dcgan_loss = gan.train_on_batch(noise, y_real)\n",
    "        \n",
    "    # Only store losses from final\n",
    "    losses[\"D\"].append((d_loss_real[0]+d_loss_fake[0])/2.)\n",
    "    losses[\"G\"].append(dcgan_loss[0])    \n",
    "        \n",
    "    print(f'Epoch: {epoch} \\t Discr. Loss Real: {d_loss_real} \\t Discr. Loss Fake: {d_loss_fake} \\t DCGAN Loss: {dcgan_loss}')\n",
    "    print(\"Time: \", time.time()-start) \n",
    "    \n",
    "    # show_images(x_fake[:8])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "VctCf6m22Hbp",
    "outputId": "6d84c758-19b1-4ee0-c72f-f2d558f33258"
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "    \n",
    "    d_loss = [v for v in losses[\"D\"]]\n",
    "    g_loss = [v for v in losses[\"G\"]]\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hzh3GWrW5f66"
   },
   "outputs": [],
   "source": [
    "def tf_norm_crop_resize_image(image, resize_dim):\n",
    "    \"\"\"Normalizes image to [0.,1.], crops to dims (150, 150, 3)\n",
    "    and resizes to `resize_dim`, returning an image tensor.\"\"\"\n",
    "    image = tf.cast(image, tf.float32)/255.\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 150, 150)\n",
    "    image = tf.image.resize(image, resize_dim)\n",
    "    image.set_shape(resize_dim + (3,))\n",
    "    return image\n",
    "\n",
    "def tf_image_pipeline(element):\n",
    "    \"\"\"Given an element drawn from the CelebA dataset.\"\"\"\n",
    "    image = element['image']\n",
    "    image = tf_norm_crop_resize_image(image,image_size)\n",
    "    return (image, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds = train_celeb.map(tf_image_pipeline).shuffle(shuffle_size).batch(batch_size).prefetch(prefetch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_gan",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
