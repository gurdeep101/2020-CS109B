{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.discussion {\n",
       "\tbackground-color: #ccffcc;\n",
       "\tborder-color: #88E97A;\n",
       "\tborder-left: 5px solid #0A8000; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small\n",
    "vocabulary_size = 10000\n",
    "\n",
    "#We also want to have a finite length of reviews and not have to process really long sentences.\n",
    "max_review_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews 25000\n",
      "Length of first and fifth review before padding 218 147\n",
      "First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "First label 1\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Number of reviews', len(x_train))\n",
    "print('Length of first and fifth review before padding', len(x_train[0]) ,len(x_train[4]))\n",
    "print('First review', x_train[0])\n",
    "print('First label', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of 1st and 5th review after padding: 500 500\n"
     ]
    }
   ],
   "source": [
    "# for feeding into RNN in batches the inputs need to be of same dimensions\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = max_review_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = max_review_length)\n",
    "print('length of 1st and 5th review after padding:', len(x_train[0]), len(x_train[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1A : FFN w/o Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 125,501\n",
      "Trainable params: 125,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 4s - loss: 176.4694 - accuracy: 0.4986 - val_loss: 85.9830 - val_accuracy: 0.5078\n",
      "Epoch 2/2\n",
      " - 3s - loss: 44.1119 - accuracy: 0.5828 - val_loss: 43.1088 - val_accuracy: 0.5088\n",
      "25000/25000 [==============================] - 2s 65us/step\n",
      "Accuracy: 50.88%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(250, activation = 'relu', input_dim = max_review_length))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 2, batch_size = 128, verbose = 2)\n",
    "scores = model.evaluate(x_test, y_test, verbose = 1)\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1B: FFN with Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 250)               12500250  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 13,500,501\n",
      "Trainable params: 13,500,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# inputs will be converted from batch size * sentence length to\n",
    "# batch_size * sentence_length * embedding_dim\n",
    "\n",
    "model.add(Embedding(vocabulary_size, embedding_dim, input_length = max_review_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 124s 5ms/step - loss: 0.5138 - accuracy: 0.7152 - val_loss: 0.2916 - val_accuracy: 0.8750\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 135s 5ms/step - loss: 0.1520 - accuracy: 0.9450 - val_loss: 0.3098 - val_accuracy: 0.8736\n",
      "Accuracy: 87.36%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 2, batch_size = 128, verbose = 1 )\n",
    "\n",
    "# Evaluate\n",
    "scores = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Accuracy: %.2f%%' % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : CNN\n",
    "\n",
    "* Text can be thought of as a 1D sequence\n",
    "* Apply 1D convolutions over a set of word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 200)          60200     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 200)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 250)               12500250  \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 13,560,701\n",
      "Trainable params: 13,560,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_dim, input_length = max_review_length))\n",
    "model.add(Conv1D(filters = 200, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 336s 13ms/step - loss: 0.1050 - accuracy: 0.9646\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 335s 13ms/step - loss: 0.0424 - accuracy: 0.9872\n",
      "Accuracy: 86.22%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 2, batch_size = 128)\n",
    "\n",
    "# evalute the CNN\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary_size, embedding_dim, input_length = max_review_length))\n",
    "model.add(SimpleRNN(100))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs = 2,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
